# Guide de Mise en Production - Bot de Scrapping

## üéØ PythonAnywhere (Recommand√©)

### √âtape 1 : Cr√©ation du compte
1. Aller sur [pythonanywhere.com](https://www.pythonanywhere.com)
2. Cr√©er un compte "Hacker" (5$/mois)
3. Acc√©der au dashboard

### √âtape 2 : Upload du code
```bash
# Option A : Git (recommand√©)
git clone https://github.com/votre-repo/scrapping-RAID.git

# Option B : Upload direct via interface web
# Zipper le projet et uploader via Files
```

### √âtape 3 : Configuration des variables d'environnement
Dans le bash console PythonAnywhere :
```bash
# Cr√©er le fichier .env
nano .env

# Ajouter vos variables :
AIRTABLE_API_KEY=votre_cl√©
AIRTABLE_BASE_ID=votre_base_id
AIRTABLE_TABLE_NAME=votre_table
AIRTABLE_VIEW_NAME=Scrapping
OPENAI_API_KEY=votre_cl√©_openai
OPENAI_ORG_ID=votre_org_id
MAKE_WEBHOOK_URL=votre_webhook_url
```

### √âtape 4 : Installation des d√©pendances
```bash
pip3.9 install --user -r requirements.txt
```

### √âtape 5 : Configuration du Cron Job
1. Aller dans l'onglet "Tasks"
2. Cr√©er une nouvelle t√¢che :
   - **Command:** `python3.9 /home/votrenom/scrapping-RAID/main.py`
   - **Hour:** 9 (9h du matin)
   - **Minute:** 0

### √âtape 6 : Test
```bash
cd scrapping-RAID
python3.9 main.py
```

## üöÄ Heroku

### √âtape 1 : Pr√©parer le projet
```bash
# Cr√©er un Procfile
echo "worker: python main.py" > Procfile

# Ajouter les buildpacks n√©cessaires
echo "https://github.com/heroku/heroku-buildpack-chromedriver" > .buildpacks
echo "https://github.com/heroku/heroku-buildpack-google-chrome" >> .buildpacks
echo "heroku/python" >> .buildpacks
```

### √âtape 2 : D√©ployer
```bash
# Installer Heroku CLI
brew install heroku/brew/heroku

# Login et cr√©ation
heroku login
heroku create votre-app-name
heroku buildpacks:add --index 1 heroku-community/multi-buildpack

# Configuration des variables
heroku config:set AIRTABLE_API_KEY=votre_cl√©
heroku config:set AIRTABLE_BASE_ID=votre_base_id
heroku config:set OPENAI_API_KEY=votre_cl√©_openai
# ... toutes les autres variables

# D√©ploiement
git add .
git commit -m "Deploy to Heroku"
git push heroku main
```

### √âtape 3 : Planifier avec Heroku Scheduler
```bash
heroku addons:create scheduler:standard
heroku addons:open scheduler
```
Ajouter une t√¢che : `python main.py` √† 9h00 chaque jour

## üåä DigitalOcean

### √âtape 1 : Cr√©er un Droplet
1. Choisir Ubuntu 20.04 LTS
2. Taille : 5$/mois (1GB RAM)
3. R√©gion : Europe (Amsterdam/Frankfurt)

### √âtape 2 : Configuration serveur
```bash
# Connexion SSH
ssh root@votre_ip

# Mise √† jour syst√®me
apt update && apt upgrade -y

# Installation Python et d√©pendances
apt install python3-pip python3-venv git -y

# Installation Chrome et ChromeDriver
wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add -
echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list
apt update
apt install google-chrome-stable -y

# Installation ChromeDriver
wget -N http://chromedriver.storage.googleapis.com/LATEST_RELEASE -O /tmp/chromedriver_version
CHROMEDRIVER_VERSION=$(cat /tmp/chromedriver_version)
wget -N http://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip -P /tmp/
unzip /tmp/chromedriver_linux64.zip -d /tmp/
chmod +x /tmp/chromedriver
mv /tmp/chromedriver /usr/local/bin/
```

### √âtape 3 : D√©ploiement du code
```bash
# Cloner le projet
git clone https://github.com/votre-repo/scrapping-RAID.git
cd scrapping-RAID

# Environnement virtuel
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Configuration des variables
cp env_example.txt .env
nano .env  # √âditer avec vos vraies valeurs
```

### √âtape 4 : Automatisation avec Cron
```bash
# Ouvrir crontab
crontab -e

# Ajouter la ligne (9h chaque jour)
0 9 * * * cd /root/scrapping-RAID && /root/scrapping-RAID/venv/bin/python main.py
```

## üí° Conseils de Production

### Monitoring
- Ajouter des logs dans `/var/log/scrapping.log`
- Configurer des alertes email en cas d'erreur
- Utiliser un service comme UptimeRobot pour surveiller

### S√©curit√©
- Utiliser des variables d'environnement (jamais de cl√©s en dur)
- Configurer un pare-feu
- Mettre √† jour r√©guli√®rement le syst√®me

### Performance
- Limiter le nombre d'entreprises trait√©es par run
- Ajouter des d√©lais entre les requ√™tes
- Utiliser un cache pour √©viter les re-scrapping

### Sauvegarde
- Sauvegarder le code sur Git
- Exporter r√©guli√®rement la configuration
- Documenter les changements

## üéâ R√©sum√©

**Ma recommandation : PythonAnywhere**
- ‚úÖ Simple √† configurer
- ‚úÖ Selenium pr√©-install√©
- ‚úÖ Cron jobs int√©gr√©s
- ‚úÖ Support technique
- ‚úÖ Prix abordable (5$/mois)

Votre bot tournera automatiquement chaque jour √† 9h sans intervention ! 